# -*- coding: utf-8 -*-
"""Test_pretrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dWswYUoGPkJaSrs0iXfhyD2U0zvsRRt2
"""

# !pip install pytorch-lightning
# !pip install git+https://github.com/PytorchLightning/pytorch-lightning-bolts.git@master --upgrade
# !pip install lightning-bolts

# Commented out IPython magic to ensure Python compatibility.
## Standard libraries
import os
from copy import deepcopy

## Imports for plotting
import matplotlib.pyplot as plt
plt.set_cmap('cividis')
# %matplotlib inline
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('svg', 'pdf') # For export
import matplotlib
matplotlib.rcParams['lines.linewidth'] = 2.0
import seaborn as sns
sns.set()

## tqdm for loading bars
from tqdm.notebook import tqdm

## PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data
import torch.optim as optim

## Torchvision
import torchvision
from torchvision.datasets import STL10
from torchvision import transforms

# PyTorch Lightning
# try:
#     import pytorch_lightning as pl
# except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary
#     !pip install --quiet pytorch-lightning>=1.4
#     import pytorch_lightning as pl
import pytorch_lightning as pl
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint

from PIL import Image
import glob
import os

# Import tensorboard
# %load_ext tensorboard

# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)
DATASET_PATH = "D:/Research/Dataset/UFI_multidisease/all_no_normal"
# Path to the folder where the pretrained models are saved
CHECKPOINT_PATH = "checkpoints"
# In this notebook, we use data loaders with heavier computational processing. It is recommended to use as many
# workers as possible in a data loader, which corresponds to the number of CPU cores
# NUM_WORKERS = os.cpu_count()
NUM_WORKERS = 0
# Setting the seed
pl.seed_everything(42)

# Ensure that all operations are deterministic on GPU (if used) for reproducibility
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

device = torch.device("cuda:0") if torch.cuda.is_available() else torch.device("cpu")
print("Device:", device)
print("Number of workers:", NUM_WORKERS)

import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

from torchmetrics.classification import MultilabelAUROC
from torchmetrics.classification import MultilabelF1Score
from torchmetrics.classification import MultilabelPrecision
from torchmetrics.classification import MultilabelRecall
from torchmetrics.classification import MultilabelSpecificity
from torchmetrics.classification import MultilabelAccuracy

# from torchmetrics.classification import MultilabelSensitivity

class ResNet(pl.LightningModule):

    def __init__(self, num_classes, lr, weight_decay, max_epochs=100):
        super().__init__()
        self.save_hyperparameters()
        self.model = torchvision.models.resnet34(pretrained=True)
        ftr = self.model.fc.in_features
        self.model.fc = nn.Linear(ftr, 6)


    def configure_optimizers(self):
        optimizer = optim.AdamW(self.parameters(),
                                lr=self.hparams.lr,
                                weight_decay=self.hparams.weight_decay)
        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,
                                                      milestones=[int(self.hparams.max_epochs*0.7),
                                                                  int(self.hparams.max_epochs*0.9)],
                                                      gamma=0.1)
        return [optimizer], [lr_scheduler]

    def _calculate_loss(self, batch, mode='train'):
        imgs, labels = batch
        preds = self.model(imgs)
        criterion = nn.BCEWithLogitsLoss()
        # loss = F.cross_entropy(preds, labels)
        loss = criterion(preds,labels.float())
        # acc = (preds.argmax(dim=-1) == labels).float().mean()
        acc = MultilabelAccuracy(num_labels=6).to(device)
        auc = MultilabelAUROC(num_labels=6, average="macro", thresholds=None).to(device)
        f1 = MultilabelF1Score(num_labels=6, threshold=0.1).to(device)
        precision = MultilabelPrecision(num_labels=6, threshold=0.8).to(device)
        recall = MultilabelRecall(num_labels=6, threshold=0.1).to(device)
        # specifity = MultilabelSpecificity(num_labels=6, threshold=0.1).to(device)

        accuracy = acc(preds, labels)
        auc_score = auc(preds, labels)
        f1_score = f1(preds, labels)
        precision_score = precision(preds, labels)
        recall_score = recall(preds, labels)
        # specifity_score = specifity(preds, labels)

        self.log(mode + '_acc', accuracy, prog_bar=True)
        self.log(mode + '_auc', auc_score, prog_bar=True)
        self.log(mode + '_f1', f1_score, prog_bar=True)
        self.log(mode + '_precision', precision_score, prog_bar=True)
        self.log(mode + '_recall', recall_score, prog_bar=True)
        self.log(mode + '_loss', loss, prog_bar=True)

        if mode=='test':
            auc_class = MultilabelAUROC(num_labels=6, average=None, thresholds=None).to(device)
            auc_score_class = auc_class(preds, labels)
            print("AUC score for each class: ", auc_score_class)

        return loss

    def training_step(self, batch, batch_idx):
        return self._calculate_loss(batch, mode='train')

    def validation_step(self, batch, batch_idx):
        self._calculate_loss(batch, mode='val')

    def test_step(self, batch, batch_idx):
        self._calculate_loss(batch, mode='test')

import os
import pandas as pd
from torchvision.io import read_image
from torch.utils.data import Dataset
class CustomImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform
        self.target_transform = target_transform
        self.label_arr = np.asarray(self.img_labels.iloc[:, 1:])

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])
        image = read_image(img_path)
        # label = self.img_labels.iloc[idx, 1]
        label = self.label_arr[idx]
        if self.transform:
            image = self.transform(image)
        if self.target_transform:
            label = self.target_transform(label)
        # print(img_path,label)
        return image, label

train_transforms = transforms.Compose([transforms.ToPILImage(),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.Resize((512,512)),
                                       transforms.RandomGrayscale(p=0.2),
                                       transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 0.5)),
                                       transforms.ToTensor(),
                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                                            std=[0.229, 0.224, 0.225])
                                       # transforms.Normalize((0.5,), (0.5,))
                                       ])
img_transforms = transforms.Compose([transforms.ToTensor(),
                                     transforms.Normalize((0.5,), (0.5,))])
from torchvision.datasets.imagenet import ImageFolder
dataset = CustomImageDataset(annotations_file="C:/Users/caust/Fundus Dataset/UFI_multidisease/labels_nohead_no_normal.csv", img_dir="C:/Users/caust/Fundus Dataset/UFI_multidisease/all_no_normal" ,transform=train_transforms)
train_img_aug_data, test_img_aug_data = torch.utils.data.random_split(dataset, [2885, 400])
# train_img_aug_data = ImageFolder("D:/Research/Dataset/UFI_multidisease/train", train_transforms)
# test_img_aug_data = ImageFolder("D:/Research/Dataset/UFI_multidisease/validate", train_transforms)

def train_resnet(batch_size, max_epochs=100, **kwargs):
    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, "ResNet_imagenet_final2"),
                         accelerator="gpu" if str(device).startswith("cuda") else "cpu",
                         devices=1,
                         max_epochs=max_epochs,
                         callbacks=[ModelCheckpoint(save_weights_only=True, mode="max", monitor="val_auc"),
                                    LearningRateMonitor("epoch")],
                         check_val_every_n_epoch=2)
    trainer.logger._default_hp_metric = None

    # Data loaders
    train_loader = data.DataLoader(train_img_aug_data, batch_size=batch_size, shuffle=True,
                                   drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)
    test_loader = data.DataLoader(test_img_aug_data, batch_size=batch_size, shuffle=False,
                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)

    # Check whether pretrained model exists. If yes, load it and skip training
    pretrained_filename = os.path.join(CHECKPOINT_PATH, "ResNet.ckpt")
    if os.path.isfile(pretrained_filename):
        print("Found pretrained model at %s, loading..." % pretrained_filename)
        model = ResNet().load_from_checkpoint(pretrained_filename, strict=False)
    else:
        pl.seed_everything(42) # To be reproducable
        model = ResNet(**kwargs)
        trainer.fit(model, train_loader, test_loader)
        model = ResNet.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)

    # Test best model on validation set
    train_result = trainer.test(model, train_loader, verbose=False)
    val_result = trainer.test(model, test_loader, verbose=False)
    result = {"train": train_result[0]["test_auc"], "test": val_result[0]["test_auc"]}
    metrics_results = {"acc": val_result[0]["test_acc"], "f1": val_result[0]["test_f1"], "precision": val_result[0]["test_precision"], "recall": val_result[0]["test_recall"]}

    return model, result, metrics_results

resnet_model, resnet_result, metrics = train_resnet(batch_size=64,
                                           num_classes=6,
                                           lr=1e-3,
                                           weight_decay=1e-3,
                                           # weight_decay=2e-4,
                                           max_epochs=100)
print(f"AUC on training set: {100*resnet_result['train']:4.2f}%")
print(f"AUC on test set: {100*resnet_result['test']:4.2f}%")

print(f"Acc on test set: {100*metrics['acc']:4.2f}%")
print(f"F1 on test set: {100*metrics['f1']:4.2f}%")
print(f"Precision on test set: {100*metrics['precision']:4.2f}%")
print(f"Recall on test set: {100*metrics['recall']:4.2f}%")
