{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_6688\\3183581016.py:9: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "# %matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## tqdm for loading bars\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "# try:\n",
    "#     import pytorch_lightning as pl\n",
    "# except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "#     !pip install --quiet pytorch-lightning>=1.4\n",
    "#     import pytorch_lightning as pl\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelPrecision\n",
    "from torchmetrics.classification import MultilabelRecall\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from torchmetrics.classification import MultilabelSpecificity\n",
    "from torchmetrics.classification import MultilabelConfusionMatrix\n",
    "from torchmetrics.classification import MulticlassAUROC\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchmetrics.classification import MulticlassPrecision\n",
    "from torchmetrics.classification import MulticlassRecall\n",
    "from torchmetrics.classification import MulticlassAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=1000):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        # Base model f(.)\n",
    "        self.convnet = torchvision.models.resnet34(num_classes=4*hidden_dim)  # Output of last linear layer\n",
    "        # The MLP for g(.) consists of Linear->ReLU->Linear\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                            T_max=self.hparams.max_epochs,\n",
    "                                                            eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode+'_loss', nll)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)],\n",
    "                             dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean(), prog_bar=True)\n",
    "        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean(), prog_bar=True)\n",
    "        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean(), prog_bar=True)\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=100):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Mapping from representation h to classes\n",
    "        # self.network = network\n",
    "        ####################################################\n",
    "        simclr = simclr_model\n",
    "        self.network = deepcopy(simclr.convnet)\n",
    "        self.network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "        self.network.eval()\n",
    "        self.network.to(device)\n",
    "        self.model = nn.Linear(512, 6)\n",
    "        #######################################################\n",
    "        # self.network = torchvision.models.resnet34(num_classes=6, pretrained=False)\n",
    "        #####################barlow#############################\n",
    "        # simclr = encoder\n",
    "        # # self.network = deepcopy(simclr.convnet)\n",
    "        # self.network = deepcopy(simclr)\n",
    "        # # self.network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "        # self.network.eval()\n",
    "        # self.network.to(device)\n",
    "        # self.model = nn.Linear(512, 6)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                      milestones=[int(self.hparams.max_epochs*0.6),\n",
    "                                                                  int(self.hparams.max_epochs*0.8)],\n",
    "                                                      gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode='train'):\n",
    "        # feats, labels = batch\n",
    "        # preds = self.model(feats)\n",
    "        # loss = F.cross_entropy(preds, labels)\n",
    "        # acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        #\n",
    "        # self.log(mode + '_loss', loss)\n",
    "        # self.log(mode + '_acc', acc)\n",
    "        imgs, labels = batch\n",
    "\n",
    "        # preds = self.network(imgs)\n",
    "\n",
    "        features = self.network(imgs)\n",
    "        preds = self.model(features)\n",
    "        # preds = torch.sigmoid(preds)\n",
    "\n",
    "        # preds = preds.squeeze()\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        labels = labels.squeeze()\n",
    "        # loss = F.cross_entropy(preds, labels)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        acc = MultilabelAccuracy(num_labels=6).to(device)\n",
    "        auc = MultilabelAUROC(num_labels=6, average=\"macro\", thresholds=None).to(device)\n",
    "        f1 = MultilabelF1Score(num_labels=6, average=\"macro\").to(device)\n",
    "        precision = MultilabelPrecision(num_labels=6, average=\"macro\").to(device)\n",
    "        recall = MultilabelRecall(num_labels=6, average=\"macro\", threshold=0.3).to(device)\n",
    "\n",
    "        # acc = MulticlassAccuracy(num_classes=5).to(device)\n",
    "        # auc = MulticlassAUROC(num_classes=5, average=\"macro\", thresholds=None).to(device)\n",
    "        # f1 = MulticlassF1Score(num_classes=5, average=\"macro\").to(device)\n",
    "        # precision = MulticlassPrecision(num_classes=5, average=\"macro\").to(device)\n",
    "        # recall = MulticlassRecall(num_classes=5, average=\"macro\", threshold=0.3).to(device)\n",
    "        # specificity = MultilabelSpecificity(num_labels=7).to(device)\n",
    "        # confusion_matrix = MultiClassConfusionMatrix(num_labels=6).to(device)\n",
    "\n",
    "        accuracy = acc(preds, labels)\n",
    "        auc_score = auc(preds, labels)\n",
    "        f1_score = f1(preds, labels)\n",
    "        precision_score = precision(preds, labels)\n",
    "        recall_score = recall(preds, labels)\n",
    "        # specificity_score = specificity(preds, labels)\n",
    "        # confusion_matrix_score = confusion_matrix(preds, labels)\n",
    "        # tn = confusion_matrix_score[:, 0, 0]\n",
    "        # tp = confusion_matrix_score[:, 1, 1]\n",
    "        # fn = confusion_matrix_score[:, 1, 0]\n",
    "        # fp = confusion_matrix_score[:, 0, 1]\n",
    "        # specificity_score_matrix = tn / (tn + fp)\n",
    "        # sensitivity_score_matrix = tp / (tp + fn)\n",
    "\n",
    "        self.log(mode + '_acc', accuracy, prog_bar=True)\n",
    "        self.log(mode + '_auc', auc_score, prog_bar=True)\n",
    "        self.log(mode + '_f1', f1_score, prog_bar=True)\n",
    "        self.log(mode + '_precision', precision_score, prog_bar=True)\n",
    "        self.log(mode + '_recall', recall_score, prog_bar=True)\n",
    "        # self.log(mode + '_specificity', specificity_score, prog_bar=True)\n",
    "        # self.log(mode + '_specificity_matrix', specificity_score_matrix.mean(), prog_bar=True)\n",
    "        # self.log(mode + '_sensitivity_matrix', sensitivity_score_matrix.mean(), prog_bar=True)\n",
    "\n",
    "        self.log(mode + '_loss', loss, prog_bar=True)\n",
    "\n",
    "\n",
    "        # if mode == 'val':\n",
    "        #     print(\"accuracy \", accuracy)\n",
    "        #     print(\"auc score \", auc_score)\n",
    "        #     print(\"f1\", f1_score)\n",
    "        #     print(\"precision\", precision_score)\n",
    "            # print(\"recall\", recall_score)\n",
    "            # print(\"specificity_matrix\", specificity_score_matrix.mean())\n",
    "            # print(\"sensitivity_matrix\", sensitivity_score_matrix.mean())\n",
    "\n",
    "        # if mode=='test':\n",
    "        #     # auc_class = MultilabelAUROC(num_labels=6, average=None, thresholds=None).to(device)\n",
    "        #     # auc_score_class = auc_class(preds, labels)\n",
    "        #     # print(\"AUC score for each class: \", auc_score_class)\n",
    "        #\n",
    "        #     acc_class =  MultilabelAccuracy(num_labels=6, average=None).to(device)\n",
    "        #     acc_score_class = acc_class(preds, labels)\n",
    "        #     print(\"Accuracy for each class: \", acc_score_class)\n",
    "        #\n",
    "        #\n",
    "        #     f1_class = MultilabelF1Score(num_labels=6, average=None).to(device)\n",
    "        #     f1_score_class = f1_class(preds, labels)\n",
    "        #     print(\"F1 score for each class: \", f1_score_class)\n",
    "        #\n",
    "        #     precision_class = MultilabelPrecision(num_labels=6, average=None).to(device)\n",
    "        #     pre_score_class = precision_class(preds, labels)\n",
    "        #     print(\"Precison for each class: \", pre_score_class)\n",
    "        #\n",
    "        #     recall_class = MultilabelRecall(num_labels=6, average=None, threshold=0.2).to(device)\n",
    "        #     recall_score_class = recall_class(preds, labels)\n",
    "        #     print(\"AUC score for each class: \", recall_score_class)\n",
    "\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label_arr = np.asarray(self.img_labels.iloc[:, 1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path+'.jpeg')\n",
    "        # label = self.img_labels.iloc[idx, 1]\n",
    "        label = self.label_arr[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        # print(img_path,label)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.imagenet import ImageFolder\n",
    "train_transforms = transforms.Compose([transforms.ToPILImage(),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                       transforms.RandomRotation(180),\n",
    "                                       transforms.Resize((512,512)),\n",
    "                                       transforms.RandomGrayscale(p=0.2),\n",
    "                                       transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 0.5)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225]),\n",
    "                                       # ToFeature(simclr_model)\n",
    "                                       # transforms.Normalize((0.5,), (0.5,))\n",
    "                                       ])\n",
    "dataset = CustomImageDataset(annotations_file=\"C:/Users/User/Fundus Dataset/UFI_multidisease/labels_nohead_no_normal.csv\",\n",
    "                             img_dir=\"C:/Users/User/Fundus Dataset/UFI_multidisease/all_no_normal\" ,transform=train_transforms)\n",
    "\n",
    "train_img_aug_data, test_img_aug_data = torch.utils.data.random_split(dataset, [2885, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.4.post0 to v2.0.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file c:\\Users\\User\\PycharmProjects\\ssl\\models\\epoch=1002-step=116348.ckpt`\n"
     ]
    }
   ],
   "source": [
    "simclr_model = SimCLR.load_from_checkpoint(\"models/epoch=1002-step=116348.ckpt\")\n",
    "model = LogisticRegression.load_from_checkpoint(\"checkpoints/dt_simclr_m4/lightning_logs/version_0/checkpoints/epoch=89-step=4140-v2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
